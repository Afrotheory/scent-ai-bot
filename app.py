import streamlit as st
import google.generativeai as genai
import os
import pandas as pd
import re

# 1. é é¢é…ç½®
st.set_page_config(page_title="Scent Curator Assistant", layout="wide")
st.title("ğŸ¯ æ±æ–¹é¦™ç¦®ï¼šä¸­é†«åˆé¦™ç™¾ç§‘å°ˆå®¶ç³»çµ±")
st.markdown("---")

# 2. åˆå§‹åŒ–å°è©±è¨˜æ†¶
if "messages" not in st.session_state:
    st.session_state.messages = []

# 3. è®€å–çŸ¥è­˜åº« (æ ¸å¿ƒï¼šå„ªå…ˆåŠ è¼‰ TCM ç™¾ç§‘)
@st.cache_data
def load_all_libraries():
    try:
        paths = {
            "tcm": "docs/TCM_Knowledge.md",
            "sop": "docs/SOP_Flow.md",
            "product": "docs/Product_Info.md",
            "sizes": "docs/Product_Sizes.md",
            "prices": "docs/Price_List.md"
        }
        lib = {}
        for key, path in paths.items():
            if os.path.exists(path):
                with open(path, "r", encoding="utf-8") as f:
                    lib[key] = f.read()
            else:
                lib[key] = "" # å®¹éŒ¯è™•ç†
        return lib
    except Exception as e:
        st.error(f"è®€å–è³‡æ–™åº«å¤±æ•—: {e}")
        return None

lib = load_all_libraries()

# 4. é…ç½® Gemini å¼•æ“
gemini_key = st.secrets.get("GEMINI_API_KEY")
if not gemini_key or not lib:
    st.error("ç³»çµ±é…ç½®æœªå®Œæˆï¼Œè«‹æª¢æŸ¥ API Key æˆ– docs æ–‡ä»¶ã€‚")
else:
    genai.configure(api_key=gemini_key)
    
    @st.cache_resource
    def get_brain():
        try:
            models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            target = next((m for m in models if 'gemini-1.5-flash' in m), models[0])
            return genai.GenerativeModel(model_name=target)
        except:
            return genai.GenerativeModel('gemini-1.5-flash')

    model = get_brain()

    # --- å´é‚Šæ¬„ï¼šæ§åˆ¶ä¸­å¿ƒ ---
    with st.sidebar:
        st.header("âš™ï¸ æ¨¡å¼åˆ‡æ›")
        mode = st.radio("ç•¶å‰ä»»å‹™ (Select Task):", 
                        ["ğŸ” è¨ºæ–·æ¨¡å¼ (Diagnosis)", "âœï¸ å‰µä½œæ¨¡å¼ (Creative/Translation)", "ğŸ“Š ç”¢å“å°èˆª (Catalog & Pricing)"])
        st.divider()
        if st.button("ğŸ§¹ æ¸…ç†å°è©±æ­·å²"):
            st.session_state.messages = []
            st.rerun()
        st.caption("AI æ ¸å¿ƒå·²é€£çµï¼šTCM_Knowledge.md")

    # 5. è¼¸å…¥ç•Œé¢ä½ˆå±€
    if mode == "ğŸ” è¨ºæ–·æ¨¡å¼ (Diagnosis)":
        user_input = st.text_area("ğŸ‘‰ ç²˜è²¼å®¢æˆ¶è«®è©¢åŸè©±:", height=180, placeholder="å®¢æˆ¶èªªè†è“‹å†·ç—›...")
        mode_instruction = f"""
        TASK: DIAGNOSTIC_ANALYSIS
        1. CROSS-REFERENCE: Use the TCM Library ({lib['tcm']}) to find the specific syndrome.
        2. SOP: Identify the stage from {lib['sop']}.
        3. MANDATORY OUTPUT: You MUST explicitly state SOP stage in Section 1, e.g. "Stage 3: Education & Storytelling".
        4. OUTPUT: Strategy -> English Response -> Translation.
        """
    elif mode == "âœï¸ å‰µä½œæ¨¡å¼ (Creative/Translation)":
        user_input = st.text_area("ğŸ‘‰ è¼¸å…¥ä½ æƒ³è¡¨é”çš„ä¸­é†«é»å­ / éŠ·å”®è¦é»:", height=180, placeholder="å‘Šè¨´ä»–é»‘é¾æ¶èƒ½æ¶ˆç©åˆ©æ°´ï¼Œå¥‘åˆçµçŸ³èª¿ç†æ€è·¯...")
        mode_instruction = f"""
        TASK: CREATIVE_TRANSLATION
        1. NO SOP: Skip SOP analysis entirely.
        2. TCM ENHANCEMENT: Extract professional logic (e.g., 'Fluid Metabolism', 'Stagnation Clearing') from {lib['tcm']} based on the user's input.
        3. POLISH: Translate the ideas into high-end, elegant English.
        """
    else:
        st.header("ğŸ“Š å…¨å“é¡ä¸­è‹±å°ç…§åŠå ±åƒ¹æ¸…å–®")
        st.info("ğŸ’¡ æç¤ºï¼šä½ å¯ä»¥ä½¿ç”¨ä¸‹è¡¨å³ä¸Šè§’çš„æ”¾å¤§é¡æˆ–æœå°‹åŠŸèƒ½å¿«é€ŸæŸ¥æ‰¾ç”¢å“åç¨±æˆ–å°ºå¯¸ã€‚")

        try:
            import pandas as pd

            catalog_data = [
                {"ç”¢å“": "éº’éºŸç«­/é¾ç‘", "English Name": "Dragon's Blood / Long Rui", "è¦æ ¼": "10mm/14mm/18mm", "ä¾›è²¨åƒ¹(ï¿¥)": "1343èµ·", "æœ€ä½æ§åƒ¹(ï¿¥)": "3298èµ·", "èµ·æ­¥å®šåƒ¹($)": "499èµ·"},
                {"ç”¢å“": "æ³£è¡€èœ€é­„", "English Name": "Soul of Shupo", "è¦æ ¼": "10mm/14mm/18mm", "ä¾›è²¨åƒ¹(ï¿¥)": "532èµ·", "æœ€ä½æ§åƒ¹(ï¿¥)": "1669èµ·", "èµ·æ­¥å®šåƒ¹($)": "267èµ·"},
                {"ç”¢å“": "é»‘é¾æ¶", "English Name": "Imperial Black Dragon Nectar", "è¦æ ¼": "10mm/14mm/18mm", "ä¾›è²¨åƒ¹(ï¿¥)": "1343èµ·", "æœ€ä½æ§åƒ¹(ï¿¥)": "3298èµ·", "èµ·æ­¥å®šåƒ¹($)": "499èµ·"},
                {"ç”¢å“": "ç´…éº/å››åˆé¦™", "English Name": "Red Musk / Four-in-One", "è¦æ ¼": "10mm/14mm/18mm", "ä¾›è²¨åƒ¹(ï¿¥)": "2567èµ·", "æœ€ä½æ§åƒ¹(ï¿¥)": "4068èµ·", "èµ·æ­¥å®šåƒ¹($)": "609èµ·"},
                {"ç”¢å“": "å®‰å®®ç‰›é»ƒ", "English Name": "An Gong Niu Huang", "è¦æ ¼": "10mm/14mm/18mm", "ä¾›è²¨åƒ¹(ï¿¥)": "1343èµ·", "æœ€ä½æ§åƒ¹(ï¿¥)": "3600èµ·", "èµ·æ­¥å®šåƒ¹($)": "542èµ·"},
                {"ç”¢å“": "å‚…å»¶å¹´", "English Name": "Fu Yan Nian (Vitality)", "è¦æ ¼": "10mm/14mm/18mm", "ä¾›è²¨åƒ¹(ï¿¥)": "2567èµ·", "æœ€ä½æ§åƒ¹(ï¿¥)": "4068èµ·", "èµ·æ­¥å®šåƒ¹($)": "609èµ·"},
                {"ç”¢å“": "æ¼¢å®®æ¤’æˆ¿", "English Name": "The Jiaofang (Warming)", "è¦æ ¼": "10mm/14mm/18mm", "ä¾›è²¨åƒ¹(ï¿¥)": "1343èµ·", "æœ€ä½æ§åƒ¹(ï¿¥)": "3298èµ·", "èµ·æ­¥å®šåƒ¹($)": "499èµ·"},
                {"ç”¢å“": "é¦¬ä¸Šæœ‰éŒ¢", "English Name": "Success & Wealth (Horse)", "è¦æ ¼": "é¦™ç‰Œ 30*36mm", "ä¾›è²¨åƒ¹(ï¿¥)": "36", "æœ€ä½æ§åƒ¹(ï¿¥)": "129", "èµ·æ­¥å®šåƒ¹($)": "-"},
                {"ç”¢å“": "äººåƒè“®èŠ±", "English Name": "Ginseng Lotus", "è¦æ ¼": "é¦™ç‰Œ 43*43mm", "ä¾›è²¨åƒ¹(ï¿¥)": "42", "æœ€ä½æ§åƒ¹(ï¿¥)": "168", "èµ·æ­¥å®šåƒ¹($)": "-"},
            ]
            df = pd.DataFrame(catalog_data)
            st.dataframe(df, use_container_width=True, hide_index=True)

            st.divider()
            st.subheader("ğŸ“ å°ºå¯¸åƒè€ƒ (Size Reference)")
            size_data = lib.get("sizes", "")
            st.markdown(size_data if size_data else "æœªæ‰¾åˆ°å°ºå¯¸è³‡æ–™ã€‚")
        except Exception as e:
            st.error(f"è¡¨æ ¼è§£æå¤±æ•—ï¼Œè«‹æ‰‹å‹•æª¢æŸ¥ Price_List.md æ ¼å¼ã€‚ éŒ¯èª¤: {e}")

        user_input = ""
        mode_instruction = ""

    if mode != "ğŸ“Š ç”¢å“å°èˆª (Catalog & Pricing)" and st.button("ğŸš€ ç”Ÿæˆå°ˆå®¶æ–¹æ¡ˆ", type="primary"):
        if not user_input:
            st.warning("è«‹è¼¸å…¥å…§å®¹ã€‚")
        else:
            if mode == "ğŸ” è¨ºæ–·æ¨¡å¼ (Diagnosis)":
                mode_specific_rule = (
                    "In Section 1, SOP stage is REQUIRED and cannot be omitted. "
                    "Also include pain-point mapping to one concrete product family."
                )
            else:
                mode_specific_rule = (
                    "In Creative mode, do not output SOP stage. Focus on polished translation and persuasive product storytelling."
                )

            # æ ¸å¿ƒæŒ‡ä»¤ï¼šå¼·åˆ¶çŸ¥è­˜åº«å„ªå…ˆ
            system_instruction = f"""
            You are a "Master Scent Therapist."
            MANDATORY: You must prioritize the facts in the provided TCM Library over general AI knowledge.

            ã€Core Librariesã€‘
            - TCM Knowledge: {lib['tcm']}
            - Product Specs: {lib['product']} | {lib['sizes']} | {lib['prices']}

            ã€Formatting Guideã€‘
            Regardless of mode, always structure as:
            ### 1. ç™‚ç™’å¸«å…§éƒ¨é‚è¼¯ (Logic & Strategy)
            - [Modes specifics: TCM diagnosis or Creative intent]
            - [Suggested chase-up strategy + Chinese translation]
            
            ### 2. å»ºè­°è‹±æ–‡å›è¦† (Mentor's Reply)
            [1-3 sentences of Zen-like, professional English.]

            ### 3. ä¸­æ–‡åƒè€ƒ (Translation)
            [Accurate Chinese translation of Section 2.]

            ã€Mode-specific Constraintã€‘
            {mode_specific_rule}
            """

            with st.spinner("AI æ­£åœ¨æ·±åº¦æª¢ç´¢ä¸­é†«çŸ¥è­˜åº«..."):
                try:
                    history = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.messages[-3:]])
                    full_query = f"{system_instruction}\n\n{mode_instruction}\nInput: {user_input}\nContext: {history}"
                    
                    response = model.generate_content(full_query)
                    answer = response.text
                    
                    # é¡¯ç¤ºæ–‡å­—çµæœ
                    st.markdown("---")
                    st.subheader("ğŸ’¡ ç”Ÿæˆçµæœ")
                    st.markdown(answer)
                    
                    # --- è¦–è¦ºåŒ–çµ„ä»¶ï¼šå¾ CSV å‹•æ…‹åŒ¹é…åœ–ç‰‡ ---
                    st.divider()
                    st.subheader("ğŸ–¼ï¸ æ¨è–¦è¦–è¦ºç´ æ")

                    @st.cache_data
                    def load_image_map():
                        csv_path = "docs/product_image_filenames.csv"
                        if os.path.exists(csv_path):
                            return pd.read_csv(csv_path)
                        return None

                    image_df = load_image_map()

                    if image_df is not None:
                        matched_products = []
                        seen_slugs = set()
                        search_corpus = f"{user_input}\n{answer}".lower()

                        # éæ­· CSV ä¸­çš„æ¯ä¸€è¡Œé€²è¡ŒåŒ¹é…ï¼ˆé—œéµè©å…¨æ–‡æª¢ç´¢ï¼‰
                        for _, row in image_df.iterrows():
                            original_name = str(row.get("Original Name", ""))
                            slug = str(row.get("English Slug", ""))

                            # å¾ç”¢å“åç¨±æå–ä¸­è‹±é—œéµè©ï¼Œæå‡åŒ¹é…æˆåŠŸç‡
                            split_tokens = re.split(r"[\\/ï¼Œ,ã€\s()ï¼ˆï¼‰\-]+", original_name)
                            keywords = [original_name, slug] + split_tokens
                            keywords = [k.strip().lower() for k in keywords if len(k.strip()) >= 2]

                            if any(k in search_corpus for k in keywords):
                                if slug not in seen_slugs:
                                    matched_products.append(row)
                                    seen_slugs.add(slug)

                        if matched_products:
                            for prod in matched_products:
                                st.write(f"âœ… **æª¢ç´¢åˆ°ç”¢å“åº«å­˜: {prod['Original Name']}**")
                                c1, c2 = st.columns(2)
                                # å¾ CSV è®€å–å°æ‡‰çš„æª”æ¡ˆå
                                style_img = f"images/{prod['Style Image Filename']}"
                                ing_img = f"images/{prod['Ingredients Image Filename']}"

                                with c1:
                                    if os.path.exists(style_img):
                                        st.image(style_img, caption=f"{prod['Original Name']} - æ¬¾å¼åœ–")
                                    else:
                                        st.warning(f"ç¼ºå°‘åœ–ç‰‡æª”æ¡ˆ: {prod['Style Image Filename']}")

                                with c2:
                                    if os.path.exists(ing_img):
                                        st.image(ing_img, caption=f"{prod['Original Name']} - é…æ–¹åŠŸæ•ˆåœ–")
                        else:
                            st.info("æœªæª¢ç´¢åˆ°ç‰¹å®šç”¢å“åœ–ç‰‡ï¼Œè«‹æª¢æŸ¥è¼¸å…¥æ˜¯å¦åŒ…å«ç”¢å“å…¨åã€‚")
                    else:
                        st.error("æ‰¾ä¸åˆ° product_image_filenames.csvï¼Œè«‹ç¢ºä¿æª”æ¡ˆå·²ä¸Šå‚³è‡³ docs/ ç›®éŒ„ã€‚")

                    st.session_state.messages.append({"role": "user", "content": user_input})
                    st.session_state.messages.append({"role": "assistant", "content": answer})

                except Exception as e:
                    st.error(f"ç”Ÿæˆå¤±æ•—: {e}")
