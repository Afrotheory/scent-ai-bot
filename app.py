import streamlit as st
import google.generativeai as genai
import os
import pandas as pd
import re

# 1. é é¢é…ç½®
st.set_page_config(page_title="Scent Curator Assistant", layout="wide")
st.title("ğŸ¯ æ±æ–¹é¦™ç¦®ï¼šä¸­é†«åˆé¦™ç™¾ç§‘å°ˆå®¶ç³»çµ±")
st.markdown("---")

# 2. åˆå§‹åŒ–å°è©±è¨˜æ†¶
if "messages" not in st.session_state:
    st.session_state.messages = []

# 3. è®€å–çŸ¥è­˜åº« (æ ¸å¿ƒï¼šå„ªå…ˆåŠ è¼‰ TCM ç™¾ç§‘)
@st.cache_data
def load_all_libraries():
    try:
        paths = {
            "tcm": "docs/TCM_Knowledge.md",
            "sop": "docs/SOP_Flow.md",
            "product": "docs/Product_Info.md",
            "sizes": "docs/Product_Sizes.md",
            "prices": "docs/Price_List.md"
        }
        lib = {}
        for key, path in paths.items():
            if os.path.exists(path):
                with open(path, "r", encoding="utf-8") as f:
                    lib[key] = f.read()
            else:
                lib[key] = "" # å®¹éŒ¯è™•ç†
        return lib
    except Exception as e:
        st.error(f"è®€å–è³‡æ–™åº«å¤±æ•—: {e}")
        return None

lib = load_all_libraries()

# 4. é…ç½® Gemini å¼•æ“
gemini_key = st.secrets.get("GEMINI_API_KEY")
if not gemini_key or not lib:
    st.error("ç³»çµ±é…ç½®æœªå®Œæˆï¼Œè«‹æª¢æŸ¥ API Key æˆ– docs æ–‡ä»¶ã€‚")
else:
    genai.configure(api_key=gemini_key)
    
    @st.cache_resource
    def get_brain():
        try:
            models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            target = next((m for m in models if 'gemini-1.5-flash' in m), models[0])
            return genai.GenerativeModel(model_name=target)
        except:
            return genai.GenerativeModel('gemini-1.5-flash')

    model = get_brain()

    # --- å´é‚Šæ¬„ï¼šæ§åˆ¶ä¸­å¿ƒ ---
    with st.sidebar:
        st.header("âš™ï¸ æ¨¡å¼åˆ‡æ›")
        mode = st.radio("ç•¶å‰ä»»å‹™ (Select Task):", 
                        ["ğŸ” è¨ºæ–·æ¨¡å¼ (Diagnosis)", "âœï¸ å‰µä½œæ¨¡å¼ (Creative/Translation)", "ğŸ“Š ç”¢å“å°èˆªè¡¨"])
        st.divider()
        if st.button("ğŸ§¹ æ¸…ç†å°è©±æ­·å²"):
            st.session_state.messages = []
            st.rerun()
        st.caption("AI æ ¸å¿ƒå·²é€£çµï¼šTCM_Knowledge.md")

    # 5. è¼¸å…¥ç•Œé¢ä½ˆå±€
    if mode == "ğŸ” è¨ºæ–·æ¨¡å¼ (Diagnosis)":
        user_input = st.text_area("ğŸ‘‰ ç²˜è²¼å®¢æˆ¶è«®è©¢åŸè©±:", height=180, placeholder="å®¢æˆ¶èªªè†è“‹å†·ç—›...")
        mode_instruction = f"""
        TASK: DIAGNOSTIC_ANALYSIS
        1. CROSS-REFERENCE: Use the TCM Library ({lib['tcm']}) to find the specific syndrome.
        2. SOP: Identify the stage from {lib['sop']}.
        3. MANDATORY OUTPUT: You MUST explicitly state SOP stage in Section 1, e.g. "Stage 3: Education & Storytelling".
        4. OUTPUT: Strategy -> English Response -> Translation.
        """
    elif mode == "âœï¸ å‰µä½œæ¨¡å¼ (Creative/Translation)":
        user_input = st.text_area("ğŸ‘‰ è¼¸å…¥ä½ æƒ³è¡¨é”çš„ä¸­é†«é»å­ / éŠ·å”®è¦é»:", height=180, placeholder="å‘Šè¨´ä»–é»‘é¾æ¶èƒ½æ¶ˆç©åˆ©æ°´ï¼Œå¥‘åˆçµçŸ³èª¿ç†æ€è·¯...")
        mode_instruction = f"""
        TASK: CREATIVE_TRANSLATION
        1. NO SOP: Skip SOP analysis entirely.
        2. TCM ENHANCEMENT: Extract professional logic (e.g., 'Fluid Metabolism', 'Stagnation Clearing') from {lib['tcm']} based on the user's input.
        3. POLISH: Translate the ideas into high-end, elegant English.
        """
    # æ¨¡å¼ 3ï¼šå…¨è‡ªå‹•ç”¢å“å°èˆªè¡¨ (å°æ¥å„ªåŒ–å¾Œçš„ CSV)
    elif mode == "ğŸ“Š ç”¢å“å°èˆªè¡¨":
        st.header("ğŸ“Š å…¨å“é¡ä¸­è‹±å°ç…§åŠå®˜æ–¹å ±åƒ¹å–®")

        csv_path = "docs/Price_List_Optimized.csv"
        if os.path.exists(csv_path):
            df_full = pd.read_csv(csv_path)

            # æœå°‹èˆ‡éæ¿¾åŠŸèƒ½
            search_q = st.text_input("ğŸ” æœå°‹ç”¢å“åç¨±ã€è¦æ ¼æˆ–åŠŸæ•ˆ:", "")
            if search_q:
                df_display = df_full[
                    df_full.astype(str).apply(
                        lambda x: x.str.contains(search_q, case=False)
                    ).any(axis=1)
                ]
            else:
                df_display = df_full

            st.dataframe(df_display, use_container_width=True, hide_index=True)

            st.success(f"âœ… å·²åŠ è¼‰å…¨éƒ¨ {len(df_full)} æ¢åƒ¹æ ¼æ•¸æ“š")
        else:
            st.error("æ‰¾ä¸åˆ° Price_List_Optimized.csvï¼Œè«‹ç¢ºèªå·²ä¸Šå‚³ã€‚")

        st.divider()
        st.subheader("ğŸ“ å°ºå¯¸åŠæ‰‹åœä½©æˆ´å»ºè­°")
        st.markdown(lib.get("sizes", "æœªæ‰¾åˆ°å°ºå¯¸è¡¨"))

        user_input = ""
        mode_instruction = ""

    if mode != "ğŸ“Š ç”¢å“å°èˆªè¡¨" and st.button("ğŸš€ ç”Ÿæˆå°ˆå®¶æ–¹æ¡ˆ", type="primary"):
        if not user_input:
            st.warning("è«‹è¼¸å…¥å…§å®¹ã€‚")
        else:
            # --- æ ¹æ“šæ¨¡å¼å‹•æ…‹ç”ŸæˆæŒ‡ä»¤ (åŠ å…¥å°ºå¯¸å°ˆæ¥­è©±è¡“) ---
            if mode.startswith("ğŸ” è¨ºæ–·æ¨¡å¼"):
                mode_logic = f"""
                TASK: DIAGNOSTIC_ANALYSIS
                1. SOP & TCM: Identify stage from {lib['sop']} and syndrome from {lib['tcm']}.
                2. SIZE EXPERT: If beads are mentioned, explain that larger beads (14mm/18mm) occupy more internal space, making the fit tighter than smaller beads.
                3. CLOSING: Always suggest offering 2 spare beads to ensure a perfect fit.
                """
            else:
                mode_logic = f"""
                TASK: CREATIVE_TRANSLATION
                1. TCM & STYLE: Use {lib['tcm']} for logic and maintain an imperial, elegant tone.
                2. OBJECTION HANDLING: Proactively address wrist size concerns. Mention that we provide 2 complimentary spare beads and explain the "Internal Space" logic for larger beads.
                """

            system_instruction = f"""
            You are a "Master Scent Therapist." 
            {mode_logic}

            ã€Library Referenceã€‘
            - Products/Prices: {lib['prices']} 
            - Precise Sizes & Counts: {lib['sizes']} (Note: 10mm=20pcs, 14mm=16pcs, 18mm=13pcs)

            ã€Professional Phrases to Integrateã€‘
            - "Since 18mm beads are bolder and thicker, they occupy more internal space on the wrist."
            - "To ensure a perfect fit, we include 2 complimentary spare beads and a professional elastic cord in your package."
            - "This allows you to customize the tension for your ultimate comfort."

            ã€Output Rulesã€‘
            - Section 2 MUST be: ### 2. å»ºè­°è‹±æ–‡å›è¦† (Mentor's Reply)
            - Section 3 MUST be: ### 3. ä¸­æ–‡åƒè€ƒ (Translation)
            - English must be 1-3 sentences, elegant, and warm.
            """

            with st.spinner("AI æ­£åœ¨æ·±åº¦æª¢ç´¢ä¸­é†«çŸ¥è­˜åº«..."):
                try:
                    history = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.messages[-3:]])
                    full_query = f"{system_instruction}\n\n{mode_instruction}\nInput: {user_input}\nContext: {history}"
                    
                    response = model.generate_content(full_query)
                    answer = response.text
                    
                    # é¡¯ç¤ºæ–‡å­—çµæœ
                    st.markdown("---")
                    st.subheader("ğŸ’¡ ç”Ÿæˆçµæœ")
                    st.markdown(answer)
                    
                    # --- è¦–è¦ºåŒ–çµ„ä»¶ï¼šå¾ CSV å‹•æ…‹åŒ¹é…åœ–ç‰‡ ---
                    st.divider()
                    st.subheader("ğŸ–¼ï¸ æ¨è–¦è¦–è¦ºç´ æ")

                    @st.cache_data
                    def load_image_map():
                        csv_path = "docs/product_image_filenames.csv"
                        if os.path.exists(csv_path):
                            return pd.read_csv(csv_path)
                        return None

                    image_df = load_image_map()

                    if image_df is not None:
                        # åªæ ¹æ“š AI å›è¦†å…§å®¹åŒ¹é…ï¼Œé¿å…æŒ‰å®¢æˆ¶åŸè©±èª¤è§¸ç™¼å¤šç”¢å“
                        answer_lower = answer.lower()
                        section2_match = re.search(
                            r"###\s*2\..*?(?=###\s*3\.|$)",
                            answer,
                            flags=re.IGNORECASE | re.DOTALL,
                        )
                        section3_match = re.search(
                            r"###\s*3\..*?$",
                            answer,
                            flags=re.IGNORECASE | re.DOTALL,
                        )
                        target_text = "\n".join(
                            s for s in [
                                section2_match.group(0).lower() if section2_match else "",
                                section3_match.group(0).lower() if section3_match else "",
                            ] if s
                        )
                        if not target_text:
                            target_text = answer_lower

                        def has_both_images(prod_row):
                            style_name = str(prod_row.get("Style Image Filename", "")).strip()
                            ing_name = str(prod_row.get("Ingredients Image Filename", "")).strip()
                            style_img = os.path.join("images", style_name)
                            ing_img = os.path.join("images", ing_name)
                            return os.path.exists(style_img) and os.path.exists(ing_img)

                        # ç¼ºåœ–æ™‚å›é€€åˆ°åŒé¡å¯ç”¨ç´ æï¼ˆç¡®ä¿ä½ æš‚æ—¶æ²¡å›¾ä¹Ÿèƒ½ç¨³å®šå±•ç¤ºï¼‰
                        fallback_slug_map = {
                            "sleep_aid": ["red_musk", "soul_of_shupo"],
                            "suhe_card": ["grand_suhe_incense"],
                            "dragon_phoenix_card": ["qi_lin_blood_resin"],
                            "horse_wealth": ["qi_lin_blood_resin"],
                            "ginseng_lotus": ["fu_yan_nian"],
                            "osmanthus_jasmine_pear": ["midnight_pear_in_the_canopy", "youthful_jasmine"],
                            "sandalwood": ["imperial_dragon_s_breath"],
                            "agarwood": ["imperial_dragon_s_breath"],
                            "epidemic_protection": ["an_gong_niu_huang", "grand_suhe_incense"],
                            "blue_imperial_plum_card": ["lake_blue_imperial_pluim"],
                            "ziwei_talisman": ["seven_fragrances_and_twelve_essences"],
                            "pine_cone": ["the_five_elemental_guardians"],
                            "blessing_comb": ["youthful_jasmine"],
                            "jasmine_lotion": ["youthful_jasmine"],
                        }

                        slug_to_row = {}
                        for _, r in image_df.iterrows():
                            slug_key = str(r.get("English Slug", "")).strip()
                            if slug_key:
                                slug_to_row[slug_key] = r

                        best_product = None
                        best_score = 0
                        stopwords = {
                            "the", "and", "for", "with", "from", "into", "this", "that",
                            "of", "in", "to", "a", "an", "is", "on", "by", "or",
                        }

                        # æ˜ç¡®åˆ«åä¼˜å…ˆï¼ˆé¿å…â€œå­”éŸ»è¿·è¿­â€è¿™ç±»æ¨èè¢«é€šç”¨è¯å¹²æ‰°ï¼‰
                        direct_alias_map = {
                            "confucian_charm_rosemary": [
                                "å­”éŸ»è¿·è¿­", "å­”éŸµè¿·è¿­", "kong yun mi die",
                                "confucius rosemary", "confucian charm rosemary", "confucian charm",
                            ],
                            "soul_of_shupo": ["èœ€é­„", "æ³£è¡€èœ€é­„", "çƒˆç«èœ€é­„", "soul of shupo", "shupo"],
                            "qi_lin_blood_resin": ["éº’éºŸç«­", "é¾™ç‘", "é¾ç‘", "dragon's blood", "qi lin blood"],
                            "imperial_dragon_s_nectar": ["é»‘é¾æ¶", "é»‘é¾™æ¶", "imperial black dragon nectar"],
                            "white_dragon_s_realm": ["ç™½é¾æ¶", "ç™½é¾™æ¶", "white dragon"],
                            "red_musk": ["ç´…éº", "çº¢éº", "å››åˆé¦™", "red musk", "four-in-one"],
                            "an_gong_niu_huang": ["å®‰å®®ç‰›é»ƒ", "å®‰å®«ç‰›é»„", "an gong niu huang"],
                            "fu_yan_nian": ["å‚…å»¶å¹´", "fu yan nian"],
                            "the_jiaofang": ["æ¼¢å®®æ¤’æˆ¿", "æ±‰å®«æ¤’æˆ¿", "jiaofang"],
                        }

                        for slug_key, aliases in direct_alias_map.items():
                            if any(alias.lower() in target_text for alias in aliases):
                                row = slug_to_row.get(slug_key)
                                if row is not None:
                                    best_product = row
                                    best_score = 999  # ç›´æ¥å‘½ä¸­ä¼˜å…ˆçº§æœ€é«˜
                                    break

                        # é¸æ“‡ã€Œæœ€åƒè¢«æ¨è–¦çš„é‚£ä¸€æ¬¾ã€ï¼Œåªå±•ç¤ºè©²ç”¢å“å…©å¼µåœ–
                        if best_score < 999:
                            for _, row in image_df.iterrows():
                                original_name = str(row.get("Original Name", ""))
                                slug = str(row.get("English Slug", ""))

                                split_tokens = re.split(r"[\\/ï¼Œ,ã€\s()ï¼ˆï¼‰\-]+", original_name)
                                keywords = [k.strip().lower() for k in ([original_name, slug] + split_tokens) if len(k.strip()) >= 2]
                                keywords = [k for k in keywords if k not in stopwords and len(k) >= 3]

                                # åŠ æƒæ‰“åˆ†ï¼šå®Œæ•´å‘½ä¸­ > slug å‘½ä¸­ > å…³é”®è¯å‘½ä¸­
                                score = 0
                                if original_name.lower() in target_text:
                                    score += 8
                                if slug.lower() in target_text:
                                    score += 8
                                score += sum(1 for k in keywords if k in target_text)

                                if score > best_score:
                                    best_score = score
                                    best_product = row

                        if best_product is not None and best_score > 0:
                            prod = best_product
                            used_fallback = False

                            if not has_both_images(prod):
                                # å…ˆå°è¯•åŒç±»æ˜ å°„å›é€€
                                raw_slug = str(prod.get("English Slug", "")).strip()
                                for fb_slug in fallback_slug_map.get(raw_slug, []):
                                    fb_row = slug_to_row.get(fb_slug)
                                    if fb_row is not None and has_both_images(fb_row):
                                        prod = fb_row
                                        used_fallback = True
                                        break

                            if not has_both_images(prod):
                                # è‹¥æ˜ å°„å›é€€ä»å¤±è´¥ï¼ŒæŒ‘é€‰â€œå¯ç”¨å›¾ç‰‡ä¸”å…³é”®è¯å¾—åˆ†æœ€é«˜â€çš„å€™é€‰
                                best_available = None
                                best_available_score = 0
                                for _, row in image_df.iterrows():
                                    if not has_both_images(row):
                                        continue
                                    name2 = str(row.get("Original Name", ""))
                                    slug2 = str(row.get("English Slug", ""))
                                    tokens2 = re.split(r"[\\/ï¼Œ,ã€\s()ï¼ˆï¼‰\-]+", name2)
                                    kws2 = [k.strip().lower() for k in ([name2, slug2] + tokens2) if len(k.strip()) >= 2]
                                    kws2 = [k for k in kws2 if k not in stopwords and len(k) >= 3]
                                    score2 = 0
                                    if name2.lower() in target_text:
                                        score2 += 8
                                    if slug2.lower() in target_text:
                                        score2 += 8
                                    score2 += sum(1 for k in kws2 if k in target_text)
                                    if score2 > best_available_score:
                                        best_available_score = score2
                                        best_available = row
                                if best_available is not None:
                                    prod = best_available
                                    used_fallback = True

                            if has_both_images(prod):
                                if used_fallback:
                                    st.info(
                                        f"åŸæ¨èäº§å“ç¼ºå›¾ï¼Œå·²è‡ªåŠ¨å›é€€åˆ°å¯å±•ç¤ºç´ æï¼š{prod['Original Name']}"
                                    )
                                st.write(f"âœ… **æ¨è–¦ç”¢å“è¦–è¦ºç´ æ: {prod['Original Name']}**")
                                c1, c2 = st.columns(2)
                                style_img = f"images/{prod['Style Image Filename']}"
                                ing_img = f"images/{prod['Ingredients Image Filename']}"

                                with c1:
                                    if os.path.exists(style_img):
                                        st.image(style_img, caption=f"{prod['Original Name']} - æ¬¾å¼åœ–")
                                    else:
                                        st.warning(f"ç¼ºå°‘åœ–ç‰‡æª”æ¡ˆ: {prod['Style Image Filename']}")

                                with c2:
                                    if os.path.exists(ing_img):
                                        st.image(ing_img, caption=f"{prod['Original Name']} - é…æ–¹åŠŸæ•ˆåœ–")
                                    else:
                                        st.warning(f"ç¼ºå°‘åœ–ç‰‡æª”æ¡ˆ: {prod['Ingredients Image Filename']}")
                            else:
                                st.warning("å·²åŒ¹é…äº§å“ï¼Œä½†æœªæ‰¾åˆ°å¯å±•ç¤ºçš„æˆå¥—å›¾ç‰‡ã€‚")
                        else:
                            st.info("æœªæª¢ç´¢åˆ°æ¨è–¦ç”¢å“ï¼Œè«‹åœ¨ç¬¬2æˆ–ç¬¬3éƒ¨åˆ†ä¸­æ˜ç¡®å†™å‡ºäº§å“åç§°ã€‚")
                    else:
                        st.error("æ‰¾ä¸åˆ° product_image_filenames.csvï¼Œè«‹ç¢ºä¿æª”æ¡ˆå·²ä¸Šå‚³è‡³ docs/ ç›®éŒ„ã€‚")

                    st.session_state.messages.append({"role": "user", "content": user_input})
                    st.session_state.messages.append({"role": "assistant", "content": answer})

                except Exception as e:
                    st.error(f"ç”Ÿæˆå¤±æ•—: {e}")
