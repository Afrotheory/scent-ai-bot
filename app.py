import streamlit as st
import google.generativeai as genai

# 1. é é¢é…ç½®
st.set_page_config(page_title="Scent Curator Assistant", layout="wide")
st.title("ğŸ¯ æ±æ–¹é¦™ç¦®è·¨å¢ƒè¡ŒéŠ·å°ˆæ¥­åŠ©æ‰‹")
st.markdown("---")

# 2. åˆå§‹åŒ–å°è©±è¨˜æ†¶
if "messages" not in st.session_state:
    st.session_state.messages = []

# 3. è®€å–çŸ¥è­˜åº« (ç·©å­˜è™•ç†)
@st.cache_data
def load_docs():
    try:
        paths = {
            "sop": "docs/SOP_Flow.md",
            "product": "docs/Product_Info.md",
            "sizes": "docs/Product_Sizes.md",
            "prices": "docs/Price_List.md"
        }
        content = {}
        for key, path in paths.items():
            with open(path, "r", encoding="utf-8") as f:
                content[key] = f.read()
        return content
    except Exception as e:
        st.error(f"è®€å–æ–‡ä»¶å¤±æ•—ï¼Œè«‹ç¢ºä¿ docs è³‡æ–™å¤¾å…§æœ‰å°æ‡‰çš„ MD æ–‡ä»¶: {e}")
        return None

docs = load_docs()

# 4. é…ç½® Gemini
gemini_key = st.secrets.get("GEMINI_API_KEY")
if not gemini_key or not docs:
    st.warning("è«‹æª¢æŸ¥ Secrets é…ç½®æˆ– docs æ–‡ä»¶æ˜¯å¦å®Œæ•´ã€‚")
else:
    genai.configure(api_key=gemini_key)

    @st.cache_resource
    def get_model():
        try:
            models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            target = next((m for m in models if 'gemini-1.5-flash' in m), models[0])
            return genai.GenerativeModel(model_name=target)
        except Exception:
            return genai.GenerativeModel('gemini-1.5-flash')

    model = get_model()

    # --- å´é‚Šæ¬„ï¼šåŠŸèƒ½èˆ‡æ¸…ç† ---
    with st.sidebar:
        st.header("âš™ï¸ è¨­å®š")
        mode = st.radio("é¸æ“‡æ“ä½œæ¨¡å¼ (Mode):",
                        ["åˆ†æå®¢æˆ¶è©¢ç›¤ (Diagnosis)", "å‰µä½œ/ç¿»è­¯å›è¦† (Creative Translation)"])
        if st.button("æ¸…é™¤å°è©±è¨˜éŒ„ (Clear Chat)"):
            st.session_state.messages = []
            st.rerun()
        st.info("ğŸ’¡ ã€Œåˆ†ææ¨¡å¼ã€ç”¨æ–¼åˆ¤æ–·å®¢æˆ¶æ„åœ–ï¼›ã€Œå‰µä½œæ¨¡å¼ã€å¹«ä½ æŠŠä¸­æ–‡é»å­è®Šç‚ºåœ°é“è‹±æ–‡ã€‚")

    # 5. ä¸»ç•Œé¢ä½ˆå±€
    if mode == "åˆ†æå®¢æˆ¶è©¢ç›¤ (Diagnosis)":
        user_input = st.text_area("ğŸ‘‰ ç²˜è²¼å®¢æˆ¶çš„åŸè©± (Paste Customer Query):", height=150, placeholder="ä¾‹å¦‚: I have trouble sleeping, what do you recommend?")
        instruction_type = "DIAGNOSTIC_ANALYSIS"
    else:
        user_input = st.text_area("ğŸ‘‰ è¼¸å…¥ä½ æƒ³è¡¨é”çš„ä¸­æ–‡è¦é» (What do you want to say?):", height=150, placeholder="ä¾‹å¦‚: å‘Šè¨´ä»–éº’éºŸç«­é©åˆé‹å‹•æå‚·ï¼Œæˆ‘å€‘éœ€è¦45å¤©çª–è—ï¼Œæ‰€ä»¥ç¾åœ¨åªæœ‰å°‘é‡ç¾è²¨ã€‚")
        instruction_type = "CREATIVE_RESPONSE"

    if st.button("ç”Ÿæˆå°ˆå®¶æ–¹æ¡ˆ (Generate)"):
        if not user_input:
            st.warning("è«‹å…ˆè¼¸å…¥å…§å®¹å†ç”Ÿæˆã€‚")
        else:
            # 6. æ ¸å¿ƒç³»çµ±æŒ‡ä»¤æ§‹å»ºï¼ˆå¼·åŒ–ç‰ˆï¼šå¼·åˆ¶åˆ†å¡Šè¼¸å‡ºï¼‰
            system_instruction = f"""
            You are a "Scent Healing Mentor." Build trust via professionalism and elegance.

            ã€Knowledge Baseã€‘
            - SOP: {docs['sop']}
            - Products: {docs['product']}
            - Sizes: {docs['sizes']}
            - Prices: {docs['prices']}

            ã€Strict Formatting Rulesã€‘
            Regardless of the mode, you MUST output in this EXACT structure:

            ### 1. å…§éƒ¨é‚è¼¯èˆ‡ç­–ç•¥ (Internal Strategy)
            - **SOPéšæ®µ/æ„åœ–**: [åˆ†æå®¢æˆ¶ç•¶å‰æ‰€è™•éšæ®µæˆ–ä½ çš„å‰µä½œæ„åœ–]
            - **æœ›èå•åˆ‡/è¿½å•ç­–ç•¥**: [å°ˆæ¥­è¨ºæ–·å»ºè­°ï¼Œä»¥åŠå¦‚æœå®¢æˆ¶æ²’å›ï¼Œéš”å¤©è©²æ€éº¼è¿½å•]
            - **è¿½å•ä¸­æ–‡ç¿»è­¯**: [å°‡ä¸Šè¿°è¿½å•çŸ­å¥ç¿»è­¯æˆä¸­æ–‡ï¼Œä¾›å“¡å·¥åƒè€ƒ]

            ### 2. å»ºè­°è‹±æ–‡å›è¦† (The Mentor's Reply)
            [Provide 1-3 sentences of elegant, warm, and natural English here. End with a question.]

            ### 3. ä¸­æ–‡åƒè€ƒ (Translation)
            [Provide the EXACT Chinese translation of the English reply above.]

            ã€Tone & Styleã€‘
            - Elegant, empathetic, and Zen-like.
            - English must be concise (max 3 sentences).
            - MODE: {instruction_type}
            """

            with st.spinner("AI æ­£åœ¨çµåˆç”¢å“çŸ¥è­˜åº«æ€è€ƒä¸­..."):
                try:
                    # ç²å–æœ€è¿‘å°è©±èƒŒæ™¯
                    history = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.messages[-3:]])

                    if instruction_type == "DIAGNOSTIC_ANALYSIS":
                        query = f"{system_instruction}\n\n[Analyze this customer]: {user_input}\n\n[History]: {history}"
                    else:
                        query = f"{system_instruction}\n\n[Translate and polish this Chinese idea into mentor-style English]: {user_input}\n\n[History]: {history}"

                    response = model.generate_content(query)

                    # 7. é¡¯ç¤ºçµæœ
                    st.markdown("---")
                    st.subheader("ğŸ’¡ å°ˆå®¶å»ºè­°æ–¹æ¡ˆ")
                    st.markdown(response.text)

                    # è¨˜éŒ„å°è©±
                    st.session_state.messages.append({"role": "user", "content": user_input})
                    st.session_state.messages.append({"role": "assistant", "content": response.text})
                except Exception as e:
                    st.error(f"ç™¼ç”ŸéŒ¯èª¤: {e}")

    # é¡¯ç¤ºæ­·å²ç´€éŒ„ (æŠ˜ç–Šé¡¯ç¤º)
    with st.expander("ğŸ“œ æŸ¥çœ‹æœ€è¿‘å°è©±æ­·å²"):
        for m in st.session_state.messages:
            st.write(f"**{m['role']}**: {m['content']}")
